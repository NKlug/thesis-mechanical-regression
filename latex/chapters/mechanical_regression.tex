\section{Mechanical Regression}

\Todo{Include figure of typical ResNet Layout}
Artificial Neural Networks are a popular method to solve the Supervised Learning problem described in Section X.
Especially Residual Neural Networks have shown great success in enabling very deep models.
As described earlier, RNNs usually consist of several Residual Blocks followed by dense mapping to the target space $Y$.
This section essentially follows Chapter 3 in \cite{owhadi20} and aims to provide a profound and comprehensive explanation of Mechanical Regression and how it can be interpreted as the continuous limit of ANNs, concretely RNNs.



We will now take a similar approach and try to approximate the target function $f^\dagger$ by a function
\begin{equation}
	f^\ast \coloneqq f \circ \Phi_L \ ,
\end{equation}
where 
\begin{equation}
	\Phi_L \coloneqq \phi_L \circ \phi_{L-1} \circ \ldots \circ \phi_1
\end{equation} 
is the composition of $L$ Residual Blocks, that is, functions $\phi_k = I + v_k$.
Here, the $v_k$ are functions mapping the input space $\cX$ onto itself and $I$ is the identity operator.
Thus, we can regard $\Phi_L$ as a large deformation of $\cX$.
$f: \cX \to \cY$ is a function mapping the deformed space to the target space $\cY$.

By default, the $v_k$ and $f$ can be arbitrary functions.
\Todo{ref: chapter on regularization in Deep Learning? At least explain further!}
Thus, as common in Machine Learning, in order to avoid overfitting the functions to the data, we penalize $v_k$s and $f$s with large norms.
For that, we introduce two RKHSs:
$\mathcal{V} \subseteq \{\cX \rightarrow \cX\}$ and $\mathcal{H} \subseteq \{\cX \rightarrow \cY\}$. 
By \cref{theo:kernel-for-rkhs} there is a Kernel associated with each RKHS.
Let $\Gamma$ be the Kernel associated with $\mathcal{V}$ and $K$ that of $\mathcal{H}$.
We then can identify $f$ and the $v_k$ as solutions to the following problem:
\begin{problem}
	\label{prob:min-v-f}
	\begin{cases}
		\text{Minimize~} & \nu \cdot \frac{L}{2} \sum_{k=1}^{L} \norm{v_k}_\mathcal{V}^2
		+ \lambda \norm{f}_\mathcal{H}^2 
		+ l((f \circ \Phi_L)(X), Y) \\
		\text{such that~} & v_1, \ldots, v_L \in \mathcal{V}, f \in \mathcal{H} \ .
	\end{cases}
\end{problem}
Here, $\nu$ and $\lambda$ are strictly positive balancing parameters.
$l$ is a (positive) loss measuring the similarity of the predicted outputs, that is, the image of $X$ under $f \circ \Phi_L$.

Utilizing the Ridge Regression Loss $l_R$ (\cref{eq:ridge-regression-loss}), we can rewrite the above minimization problem as
\begin{problem}
	\begin{cases}
		\text{Minimize~} & \nu \cdot \frac{L}{2} \sum_{k=1}^{L} \norm{v_k}_\mathcal{V}^2
		+ l_R(\Phi_L(X), Y) \\
		\text{such that~} & v_1, \ldots, v_L \in \mathcal{V}\ .
	\end{cases}
\end{problem}
By "hiding" the regularity of $f$ in the loss we can for now focus on the functions $v_k$.
For our calculations we will therefore only assume that $l: \cX^N \times \cY^N \rightarrow$ is a positive, continuous loss function.
If desired we can later balance the $v_k$ with the regularity of $f$ by choosing the loss appropriately.

Our main goal will now be to show that the minimization problem in \cref{prob:min-v-f} can in fact be considered as a discrete solver of a mechanical system.
In order to do that, we first reformulate the problem by introducing additional variables $q_{i,j}$ with $2 \leq i \leq L+1$, $1 \leq j \leq N$:
\begin{align}
	q_{1, j} &\coloneqq X_j \, \\
	q_{i, j} &\coloneqq (\phi_{i-1} \circ \ldots \circ \phi_1) (X_j) \ .
\end{align}
Write $q_i$ for the vector with entries $q_{i,j}$ and hence we get $q_1 = X$ and $q_i = \phi_i(q_{i-1})$.
Regard the following minimization problem:
\begin{problem}
	\label{prob:min-q}
	\begin{cases}
		\text{Minimize~} & \nu \cdot \frac{1}{2} \sum_{k=1}^{L} \frac{(q_{k+1} - q_k)^\mathrm{T}}{\Delta t} \mathbf{\Gamma}(q_k, q_k)^{-1} \left(\frac{q_{k+1} - q_k}{\Delta t}\right) \Delta t+ l(q_{L+1}, Y) \\
		\text{such that~} & q_1 = X \text{~and~} q_2, \ldots, q_{L+1} \in \cX^N \ .
	\end{cases}
\end{problem}
We will now prove that \cref{prob:min-q} is in fact equivalent to \cref{prob:min-v-f} and, assuming we know the solution to the latter problem, provides us with an explicit solution for the $v_k$s.

\begin{theorem}
	$v_1, \ldots, v_L \in \mathcal{V}$ minimize \cref{prob:min-v-f} 
	$\Leftrightarrow$
	$q_1, \ldots, q_{L+1} \in \cX^N$ minimize \cref{prob:min-q} and
	$v_k(x) = \mathbf{\Gamma}(x, q_k)^\mathrm{T}\mathbf{\Gamma}(q_k, q_k)^{-1} (q_{k+1} - q_k)$.
\end{theorem}
\begin{proof}
	Using the above defined $q_k$ we have $v_k(q_k) = q_{k+1} - q_k$ for all $k \in [L]$.
	With that we can rewrite \cref{prob:min-v-f} as
	\begin{problem}
		\label{prob:min-q-v}
		\begin{cases}
			\text{Minimize~} & \nu \cdot \frac{L}{2} \sum_{k=1}^{L} \norm{v_k}_\mathcal{V}^2
			+ l(q_{L+1}, Y) \\
			\text{such that~} & v_1, \ldots, v_L \in \mathcal{V},\ \forall k \in [L]: v_k(q_k) = q_{k+1} - q_k, \\
			& q_1 = X \text{~and~} q_2, \ldots, q_{L+1} \in \cX^N \ .
		\end{cases}
	\end{problem}
	Here we just added the $q_k$ as additional variables but then bound them to certain values, concretely $q_{k+1} = q_k + v_k(q_k) = \phi_k(q_k)$, with $q_1 = X$.
	Recursively we get $q_{L+1} = \Phi_L(X)$ which means the target function remains the same as in \cref{prob:min-v-f}.
	Note that even though we seemingly added restraints to the domains of the $v_k$ they are still the same: We just have to choose $q_{k+1}$ accordingly (which we can, as it is unconstrained).
	
	We will now derive closed form expressions for the $v_k$ as a function of the $q_k$.
	For that, let $q_k \in \cX^N$, $2 \leq k \leq N$ be arbitrary but fixed .
	This means $l(q^{L+1}, Y)$ is constant and $v_k \in V_{k, q} \coloneqq \{v \in \mathcal{V}~|~ v_k(q_k) = q_{k+1} - q_k\}$.
%	These sets remain convex: Let $\lambda \in [0, 1]$ and $v_{k, 1}, v_{k, 2} \in V_{k, q}$, then we get
%	\begin{align}
%		(\lambda v_{k, 1} + (1 - \lambda) v_{k, 2})(q_k) &= (\lambda v_{k, 1})(q_k) + ((1 - \lambda) v_{k, 2})(q_k)\\
%		&=\lambda(q_{k+1} - q_k) + (1 - \lambda)(q_{k+1} - q_k)\\
%		&= q_{k+1} - q_k \ .
%	\end{align}
	We end up with a problem of the following form:
	\begin{problem}
		\begin{cases}
			\text{Minimize} &\sum_{i=1}^n f_i(x_i)\\
			\text{such that} & \forall i \in [n]: x_i \in A_i \ ,
		\end{cases}
	\end{problem}
	with bounded $f_i: A_i \rightarrow \R$.
	One can easily verify that minimization problems of this type have a global minimum at $x_i^\ast = \argmin\{f_i(x_i)~|~ x_i \in A_i\}$, the boundedness ensuring that at least one such minimum exists.

	Thus, we have to find the minima of $\min\{\norm{v_k}_\mathcal{V}^2~|~ v_k \in \mathcal{V}, v_k(q_k) = q_{k+1} - q_k\} = l_{\text{OR}}(q_k, q_{k+1} - q_k)$, $l_{\text{OR}}$ being the optimal recovery loss from \cref{sec:optimal-recovery}.
	From that section we conveniently get the following representations for the minimal $v_k$ and the target value:
	\begin{align}
		v_k & = \mathbf{\Gamma}(x, q_k)^\mathrm{T}\mathbf{\Gamma}(q_k, q_k)^{-1} (q_{k+1} - q_k)\\
		\norm{v_k}_\mathcal{H}^2 &= (q_{k+1} - q_k)^\mathrm{T} \mathbf{\Gamma}(q_k, q_k)^{-1} (q_{k+1} - q_k)
	\end{align}
	Here, $\mathbf{\Gamma}$ is the block operator matrix with entries $\Gamma(q_{k,i}, q_{k, j})$ and $\mathbf{\Gamma}(x, q_k)$ the vector $(\Gamma(x, q_{k, i}))_{i \in [N]}$.
	++
	Having now computed optimal $v_k$ -- or rather their squared $\mathcal{H}$-norms -- as a function of $q_2, \ldots, q_{L+1}$ we can reformulate \cref{prob:min-q-v} without the $v_k$ as variables.
	Define $\Delta t \coloneqq \frac{1}{L}$.
	We get:
	\begin{problem}
		\begin{cases}
			\text{Minimize~} & \nu \cdot \frac{1}{2} \sum_{k=1}^{L}  
			\left(\frac{q_{k+1} - q_k}{\Delta t}\right)^\mathrm{T} \mathbf{\Gamma}(q_k, q_k)
			\left(\frac{q_{k+1} - q_k}{\Delta t}\right) \cdot \Delta t
			+ l(q_{L+1}, Y) \\
			\text{such that~} & q_1 = X \text{~and~} q_2, \ldots, q_{L+1} \in \cX^N \ .
		\end{cases}
	\end{problem}
	As all steps and transformations hold true in both ways, this concludes the proof.
\end{proof}

\subsection{Least Action Principle}

Take a closer look at the first term of the objective function in \cref{prob:min-q} (the parameter $\nu$ has been deliberately omitted here):
\begin{equation}
	\label{eq:discrete-lagrangian}
	\frac{1}{2} \sum_{k=1}^{L} \left(\frac{q_{k+1} - q_k}{\Delta t}\right)^\mathrm{T} \mathbf{\Gamma}(q_k, q_k)^{-1} \frac{q_{k+1} - q_k}{\Delta t} \Delta t \ .
\end{equation}
With some imagination this very much looks like an approximation of the integral of some continuous function with a step function using $L$ intervals of width $\Delta t$.
This would require the sequence $q_k$ to be a discrete equidistant sampling of a function $q: A \rightarrow \cX^N$, where $A$ is an interval in $\R$.
Without loss of generality we choose $A = [0, 1]$ and write $q_k = q(k \Delta t)$.
This way, $\frac{q_{k+1} - q_k}{\Delta t}$ can be interpreted as a forward differential quotient approximating the derivative $\dot{q}$ on at the point $k \Delta t = \frac{k}{L}$ and we get the approximation
\begin{equation}
	\left(\frac{q_{k+1} - q_k}{\Delta t}\right)^\mathrm{T} \mathbf{\Gamma}(q_k, q_k)^{-1} \frac{q_{k+1} - q_k}{\Delta t} 
	\approx \dot{q}\left(\frac{k}{L}\right)^\mathrm{T} \mathbf{\Gamma}\left(q\left(\frac{k}{L}\right), q\left(\frac{k}{L}\right)\right)^{-1}\dot{q}\left(\frac{k}{L}\right)
\end{equation}
This leads us to the obvious question if the solutions of the problem in \cref{prob:min-q} are also approximating the solutions of a similar continuous problem.
As it turns out, they do.
Consider 
\begin{equation}
\label{eq:action}
	\mathcal{A}(q) \coloneqq \int_{0}^{1} \fL(q, \dot{q}, t) \mathrm{d}t \ ,
\end{equation}
with

\begin{equation}
\label{eq:lagrangian}
	\fL(q, \dot{q}, t) \coloneqq \frac{1}{2} \dot{q}(t)^\mathrm{T} \mathbf{\Gamma}(q(t), q(t))^{-1} \dot{q}(t) \ .
\end{equation}
\Todo{Mention difference and similarity between physical and mathematical approach in definition of Lagrangian}
Here, the Lagrangian is a quadratic form.
In a physical interpretation, the Lagrangian above resembles that of a system of free moving particles who don't interact with each other.
It usually represents the kinetic energy $T$ of the system.
This interpretation would imply that in our case, the potential energy $U$ of the system is $0$.

As a result, we get the following theorem.
\begin{theorem}
	The minimal value of \cref{prob:min-q} converges towards the minimal value of             
	\info{Theorem 3.11 from paper} 
	\begin{problem}
	\label{prob:cont-least-action}
		\begin{cases}
			\text{Minimize~} & \nu \mathcal{A}(q) + l(q(1), Y)\\
			\text{such that~} & q \in C^1([0,1], \cX^N),\ q(0) = X \ .
		\end{cases}
	\end{problem}
\end{theorem}
As usual, $C^1([0,1], \cX^N)$ is the set of continuously differentiable functions $q: [0, 1] \rightarrow \cX^N$.
We will save the proof for later.

\Todo{Link between mathematical approach, i.e. variational calculus, and physical approach: Physical "interpretation" can be derived from mathematical approach + some axioms}
Equations \ref{eq:action} and \ref{eq:lagrangian} closely resemble characteristic equations from the framework of Lagrangian and Hamiltonian mechanics.
Within that framework, $q$ is the trajectory of the particle, $\fL$ the \emph{Lagrangian function} and $\mathcal{A}$ the \emph{Action}.
In our case, each training sample constitutes a particle, therefore $q$ -- a vector -- describes the trajectories of not one, but $N$ particles.
We will now explore if the rich theory of Lagrangian physics can help us analyze our problem.

The action is the integral over the Lagrangian between two points in time $t_1, t_2$.
Here, we chose $t_1 = 0$ and $t_2 = 1$.
One core principle in Lagrangian Mechanics is \emph{Hamilton's Principle}, also called the \emph{Principle of Least Action}.
It states that
\Todo{Citation needed!}
the evolution of $q$ over time between two states $q(t_1)$ and $q(t_2)$ at times $t_1$ and $t_2$ is a stationary point of the action $\mathcal{A}$.
We do not have the time to dive deeper into the underlying theory, but the interested reader is referred to \Todo{References, one of them could be Feynman lectures 2 chapter 19}.
Note that "Principle of Least Action" is a misnomer and should rather be "Principle of Stationary Action".


Hamilton's principle has a strong physical background:
The true evolution of a system $q$ between two states $q(t_1)$ and $q(t_2)$ is a stationary point of the action.
\Todo{Why doesn't the endpoint have to be fixed? This is e.g. mentioned in Classical Mechanics by Goldstein p45}

The path of least action need not always be the path for which the action becomes minimal, but rather stationary.
However, if we can show that there exists a minimum of \cref{prob:cont-least-action}, this will, \Todo{Why exactly -- do we have some similar theorem like "partial derivative zero implies extremum?"}by ..., be a point of stationary action

Let $q(1)$ be arbitrary but fixed.
Then a minimizer $q^\ast$ of \cref{prob:cont-least-action} with $q^\ast(1) = q(1)$ is a minimizer of $\mathcal{A}(q)$.
By [Kielhöfer - Variationsrechnung, Satz 1.4.2] it follows that $q^\ast$ fulfills the Euler-Lagrange equation:
\begin{equation}
	\frac{\mathrm{d}}{\mathrm{d}t} \frac{\partial \fL}{\partial \dot{q}} - \frac{\partial \fL}{\partial q} = 0 \ .
\end{equation}
Bear in mind that $q$ is a vector.
So to be precise, we would have to write $N$ Euler-Lagrange equations, one for each $q_i$ (just imagine $q_i$ and $\dot{q}_i$ in the equation above).
Nonetheless, in the following we can always treat all $q_i$ the same.
So for the sake of readability and convenience we will stick to the vector notation, which together with block operator matrices allows concise formulation.
The Euler-Lagrange equation with the Lagrangian from \cref{eq:lagrangian} reads
\begin{equation}
\label{eq:concrete-lagrangian}
	\frac{\mathrm{d}}{\mathrm{d}t} \left(\mathbf{\Gamma}(q, q)^{-1} \dot{q} \right)
	= \frac{\partial}{\partial q} \left(\frac{1}{2} \dot{q}^\mathrm{T} \mathbf{\Gamma}(q, q)^{-1} \dot{q}\right) \ .
\end{equation}

As this is true for all endpoints $q(1)$, it especially holds true for the value for which the whole expression is minimal.

\subsection{Hamiltonian Representation}

An alternative formulation of Lagrangian mechanics is the Hamiltonian formalism.
In its own, it does not add anything particularly new but rather gives us a more powerful framework to work with the already established theory.
In essence, a change of variables from $(q, \dot{q}, t)$ to $(q, p, t)$ is applied through a certain kind of transformation called \emph{Legendre transformation}.
The obtained $(q, p)$ are known as the \emph{canonical variables}, concretely canonical coordinate and canonical momentum.
We will briefly derive the Hamiltonian formulation for our application, but not cover all the theoretical details.
For a complete formal derivation from a physical point of view, see \cite[Chapter~8]{goldstein01}.
For a more mathematical approach, see \cite[Chapter~2]{marsden10}.

First, define the canonical momentum
\begin{equation}
	p = \frac{\partial \fL}{\partial \dot{q}} \ .
\end{equation}
Note that just as we actually had $N$ Euler-Lagrange Equations above, we now also have $N$ canonical momenta, each defined as $p_i = \frac{\partial \fL}{\partial \dot{q}_i}$.
Again, we use vector notation, and call $p$ \emph{the} canonical momentum.
Next, we define the \emph{Hamiltonian function}, often also called \emph{energy function} \cite{marsden10}:
\begin{equation}
	\fH(q, p, t) = p(t)^\mathrm{T}\dot{q}(t) - \fL(q, \dot{q}, t)
\end{equation}
In physical context, $\fH$ can often be expressed as the sum of the system's kinetic and potential energies.
Hence $\fH$ is a measure of the total energy of the system.

The next theorem describes the correspondence between Lagrangian and Hamiltonian mechanics:
\begin{theorem}
	If $q$ minimizes \cref{prob:cont-least-action}, $(q, p)$ follow Hamilton's equations
	\begin{equation}
	\label{eq:hamiltonian-system}
		\begin{split}
				\dot{q} &= \frac{\partial \fH(q, p)}{\partial p} = \mathbf{\Gamma}(q, q) p\\
			\dot{p} &= -\frac{\partial \fH(q, p)}{\partial q} 
			= -\frac{\partial \left(\frac{1}{2} p^\mathrm{T} \mathbf{\Gamma}(q, q) p\right)}{\partial q}
		\end{split}
	\end{equation}
	with $q(0) = X$.
\end{theorem}
\begin{proof}
	Let $q$ be a minimizer of \cref{prob:cont-least-action}.
	Then $q(0) = X$ and, as we have seen, $q$ fulfills the Euler-Lagrange equations.
	The claim immediately follows from the equivalence of the Euler-Lagrange equations and Hamilton's equations, as can be seen in e.g. \cite{marsden10, goldstein01}.
\end{proof}

From $\frac{\partial \fL}{\partial t} = 0$ it follows that
\Todo{Think about whether to keep this. Seems kind of irrelevant}
\begin{corollary}
	Along $q$ the energy is preserved.
\end{corollary}
\begin{proof}
	The Lagrangian is not explicitly time dependent, that is $\frac{\partial \fL}{\partial t} = 0$.
	Therefore
	\begin{equation}
		\frac{\mathrm{d}}{\mathrm{d} t} \fL = \sum_{i=1}^{N}\left(\frac{\partial \fL}{\partial q_i} \dot{q_i} + \frac{\partial \fL}{\partial \dot{q_i}} \ddot{q_i} \right )
		=\sum_{i=1}^{N}\left( \left( \frac{\mathrm{d}}{\mathrm{d} t} \frac{\partial \fL}{\partial \dot{q_i}} 
		\right)\dot{q_i}+ \frac{\partial \fL}{\partial \dot{q_i}} \ddot{q_i}\right )
		= \frac{\mathrm{d}}{\mathrm{d} t} \left(\sum_{i=1}^{N} \frac{\partial \fL}{\partial \dot{q_i}} \dot{q_i}\right) \ .
	\end{equation}
	It follows that
	\begin{equation}
		0 = \frac{\mathrm{d}}{\mathrm{d} t} \left( \left(\sum_{i=1}^{N} \frac{\partial \fL}{\partial \dot{q_i}} \dot{q_i} \right) -  \fL \right) 
		= \frac{\mathrm{d}}{\mathrm{d} t} \left( \fL - \sum_{i=1}^{N} p_i \dot{q_i}\right)
		= \frac{\mathrm{d}}{\mathrm{d} t} \fH \ ,
	\end{equation}
	which means that the energy function does not change over time and hence is constant.
\end{proof}

Just as before, $q(1)$ was unknown, now, $p(0)$ is to be determined.
This means we our problem now reduces to the search for the initial momentum $p(0)$.


Our next task will be to show that the system in \cref{eq:hamiltonian-system} does have a unique solution.

\subsection{Geodesic Shooting}

\subsection{Continuous Limit and Adherence Values}

\input{chapters/continuous_limit}