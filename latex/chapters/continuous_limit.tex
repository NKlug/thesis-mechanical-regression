\Todo{This section is still work in progress.}

The only thing left to prove now is that as $L \rightarrow \infty$, \cref{prob:min-q} does indeed converge towards \cref{prob:cont-least-action}.

\input{figures/figure_convergence_sketch}

This is equation 1.12 from \cite{owhadi20}.
See how this fits here
\begin{equation}
	\label{eq:phi-v-differential-equation}
	\dot{\Phi}^v(x, t) = \mathbf{\Gamma}(\Phi^v(x, t), q) p
\end{equation}

Let $C([0, 1], \cV)$ be the space of continuous functions $v: [0, 1] \times \cV$, such that the function $v(t)(x)$ is globally Lipschitz in $t$ and $x$.
For simplicity, we will write $v(t, x)$ instead of $v(t)(x)$.
Let $\Phi_v \in C([0, 1], \cV)$ be the solution to the following initial value problem.
\begin{equation}
	\begin{cases}
		&\dot{\Phi}(t, x) = v(\Phi(t, x))\\
		&\Phi(0, x) = x \ .
	\end{cases}
\end{equation}
$\dot{\Phi}(t, x)$ signifies the time derivative $\frac{\mathrm{d}}{\mathrm{d}t}\Phi$.

The idea is that $\Phi_L \stackrel{L \rightarrow \infty}{\longrightarrow} \Phi$ in the sense that for $k \in [L]$, $\phi_k \circ \phi_{k-1} \circ \cdots \circ \phi_1$ is an approximation to $\Phi_v(\frac{k}{L}, \cdot)$.
Similarly, $v_k$ from the discrete formulation approximates $v(\frac{k}{L}, \cdot)$.

\begin{problem}
	\label{prob:resnet-limit}
	\begin{cases}
		\text{Minimize~}& \frac{\nu}{2} \int_{0}^{1} \norm{v(t)}_\cV^2 \mathrm{d}t
		+ l(\Phi_v(1, X), Y)\\
		\text{such that~}& v \in C([0, 1], \cV)\\
	\end{cases}
\end{problem}
Here $\Phi_v(1, X)$ denotes the vector $(\Phi_v(t, X_i))_{i \in [N]}$.

\begin{theorem}
	\label{theo:v-q-continuous-problem-equivalence}
	$v$ minimizes \cref{prob:resnet-limit} if and only if $v$ fulfills
	\begin{equation}
			\dot{\Phi}^v(x, t) = \mathbf{\Gamma}(\Phi^v(x, t), q_t) \bGamma(q_t, q_t)^{-1} \dot{q}_t
	\end{equation}
	such that $\Phi(x, 0) = x$ for all $x \in X$ and $q$ minimizes \cref{prob:cont-least-action}.
\end{theorem}
The proof of this theorem is very similar to that of \cref{theo:v-q-problem-equivalence}, only that the discrete elements $q_k \in \cX^N$ are replaced by one continuous function $q: [0, 1] \rightarrow \cX^N$.
Within the scope of this thesis, we can only review the main ideas.
\begin{proof}
	First, define the function $q: [0, 1] \rightarrow \cX^N$ by as the vector with elements
	\begin{equation}
		q_i(t) \coloneqq \Phi_v(t, X_i) \ .
	\end{equation}
	Then $\Phi_v(1, X_i) = q_i(t)$ and thus $l(\Phi_v(1, X)) = q(1)$.
	Furthermore $\dot{q_i}(t) = \dot{\Phi}_v(t, X_i)$, or in short $\dot{q}(t) = \dot{\Phi}_v(t, X)$.
	Because $\Phi_v$ satisfies \cref{eq:phi-v-differential-equation}, it follows that
	\begin{equation}
		\dot{q}(t) = v(t, \Phi_v(t, X)) \ .
	\end{equation}
	Now, the idea is that if $t \rightarrow \min \norm{v(t, \Phi_v(t, \cdot))}_\cV^2$ is in $C([0, 1], \cV)$ -- which requires continuity and the global Lipschitz property -- this function is a minimizer of \cref{prob:resnet-limit}.
	For fixed $t \in [0, 1]$, we face an optimal recovery problem:
	\begin{equation}
		\min\{\norm{v(t, \Phi_v(t, \cdot))}_\cV^2\ |\ v(t, \Phi_v(t, X)) = q(t)\} \ .
	\end{equation}
	\cref{eq:optimal-recovery-f} provides an explicit solution to this problem, which is:
	\begin{equation}
		v(t, \Phi_v(t, x)) = \bGamma(\Phi^v(t, x), q(t))\bGamma(q(t), q(t))^{-1}\dot{q}(t) \ .
	\end{equation}
	One can verify that this function is $C([0, 1], \cV)$.
\end{proof}

\subsubsection{Existence of Minimizers}

We already saw the equivalence of \cref{prob:cont-least-action,prob:geodesic-shooting,prob:resnet-limit}, in the sense that their minimizers bijectively correspond to each other -- that is, if they exist.
Now we will show that there do indeed exist such minimizers and also that the problems' minimal values are identical.
\begin{theorem}[Existence of minimizers for the continuous problems]
	\label{theo:continuous-solutions-existence}
		There exist minimal points for \cref{prob:cont-least-action,prob:geodesic-shooting,prob:resnet-limit} and their minimal values are identical.
\end{theorem}

\Todo{Check with paper again. In the paper the equation for p might be wrong...}
\begin{equation}
	\label{eq:discrete-hamiltonian-system}
	\begin{split}
		q_{k+1} &= q_k + \Delta t \bGamma(q_k, q_k) p_k\\
		p_{k+1} &= p_k + \frac{\Delta t}{2} \grad_{q_{k+1}} \left(p_{k+1}^\T \bGamma(q_{k+1}, q_{k+1}) p_k\right)\ .
	\end{split}
\end{equation}

\begin{problem}
\label{prob:discrete-geodesic-shooting}
	\begin{cases}
		\text{Minimize~} & \frac{\nu}{2} \sum_{k=1}^L p_k^\T \bGamma(q_k, q_k) p_k \Delta t + l(q_{L+1}, Y)\\
		\text{such that~} & p_k = \bGamma(q_k, q_k)^{-1} \frac{q_{k+1} - q_k}{\Delta t},\ q_1 = X \\
		&\text{~and~} (q_k, p_k) \text{~follow the discrete Hamiltonian equations \ref{eq:discrete-hamiltonian-system}}\ .
	\end{cases}
\end{problem}
Again, for later reference we explicitly define the target function again as
\begin{equation}
	\fV_L(p_1, X, Y) \coloneqq \frac{\nu}{2} \sum_{k=1}^L p_k^\T \bGamma(q_k, q_k) p_k \Delta t + l(q_{L+1}, Y) \ .
\end{equation}

\begin{theorem}
	\label{theo:discrete-shooting-min-q-equivalence}
	\cref{prob:discrete-geodesic-shooting} and \cref{prob:min-q} are equivalent.
\end{theorem}

\begin{theorem}[Existence of solutions to the discrete problems]
	\label{theo:discrete-solutions-existence}
	There exist minimal points for \cref{prob:discrete-geodesic-shooting,prob:min-v-f,prob:min-q} and their minimal values are identical.
\end{theorem}


\subsubsection{Convergence}

The following theorem is quite a big one.
It states convergence results for all three discrete problems we have dealt with so far.
Let $M_L(X, Y)$ be the set of minimizers of \cref{prob:discrete-geodesic-shooting}.
Respectively, let $M(X, Y)$ be the set of minimizers of \cref{prob:geodesic-shooting}.
\cref{theo:continuous-solutions-existence,theo:discrete-solutions-existence} imply that both sets are non-empty.
\begin{theorem}[Convergence theorem]
	\label{theo:problem-convergence}
	The minimal value of \cref{prob:discrete-geodesic-shooting,prob:min-q,prob:min-v-f} converges towards the minimal value of \cref{prob:cont-least-action,prob:geodesic-shooting,prob:resnet-limit} as $L \rightarrow \infty$.
	Furthermore,
	\begin{equation}
	\label{eq:limit-adherence}
		\bigcap_{L' \in \mathbb{N}} \closure\left(\bigcup_{L' \geq L} M_L(X, Y)\right) = M(X, Y) \ .
	\end{equation}
\end{theorem}
Here, $\closure (A)$ is the closure of the set $A$.
Note that \cref{eq:limit-adherence} means that the adherence values of $M_L(X, Y)$ converge towards $M(X, Y)$ as $L \rightarrow \infty$.
The proof we will now conduct is the highlight of this section:
It involves everything we have done thus far.
\begin{proof}
	Sketch (for now).
	
	We know by \dots that we can parameterize the minimal values and points by the initial momentum $p_1$ and $p(0)$ for the discrete and continuous geodesic shooting problem, respectively.
	This means if suffices to show the convergence of $\fV_L(p_1, X, Y)$ towards $\fV(p(0), X, Y)$.
\end{proof}